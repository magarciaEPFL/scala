<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="A new backend and optimizer for scalac : Faster compilation, faster runs" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>A new backend and optimizer for scalac</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/magarciaEPFL/scala">View on GitHub</a>

          <h1 id="project_title">A new backend and optimizer for scalac</h1>
          <h2 id="project_tagline">Faster compilation, faster runs</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/magarciaEPFL/scala/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/magarciaEPFL/scala/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p><em>Last updated: January 23rd, 2014</em></p>

<h1>
<a name="toc" class="anchor" href="#toc"><span class="octicon octicon-link"></span></a>TOC</h1>

<ol>
<li><a href="#Goodies">Goodies</a></li>
<li><a href="#WhatsNew">What's new in the new optimizer</a></li>
<li><a href="#TestDriving">Test driving the new optimizer</a></li>
<li><a href="#GettingStarted">Getting Started</a></li>
<li><a href="#Paces">Putting the new optimizer through its paces</a></li>
<li><a href="#FAQ">FAQ</a></li>
<li><a href="#FeedbackWelcome">Comments, benchmarks, test cases, bug reports, are welcome</a></li>
</ol><h1>
<a name="1-goodies" class="anchor" href="#1-goodies"><span class="octicon octicon-link"></span></a><a name="Goodies">1</a> Goodies</h1>

<p>The experimental branch <code>GenRefactored99sR</code> at repo <a href="https://github.com/magarciaEPFL/scala">https://github.com/magarciaEPFL/scala</a> improves three areas of <code>scalac</code>: optimizer, code emitter, and AST-level representation of closures. The resulting compiler is on average 15% faster, and also emits more compact code than the mainline Scala compiler.</p>

<p>A small subset of the above functionality has already been merged and will be available in Scala 2.11 once it's released. However, the bulk of the new backend won't. For all practical purposes, don't use that small "subset" available in <code>scalac</code>. You'll be missing on the delta with respect to full-blown new backend, and it's a huge delta:</p>

<ul>
<li><a href="https://github.com/magarciaEPFL/scala/compare/master...GenRefactored99sR">https://github.com/magarciaEPFL/scala/compare/master...GenRefactored99sR</a></li>
</ul><p>To get up and running, please skip to <a href="#GettingStarted">Getting Started</a>.</p>

<h2>
<a name="11-why-a-new-optimizer" class="anchor" href="#11-why-a-new-optimizer"><span class="octicon octicon-link"></span></a>1.1 Why a new optimizer</h2>

<p>It might be the officially supported optimizer, but not everyone likes it. It's very telling a major Scala framework <a href="http://doc.akka.io/docs/akka/snapshot/intro/getting-started.html">recommends against using it</a>.</p>

<p>You might also have heard "everything will be better with MethodHandles". Well, who knows, it might turn out that way in the end. Instead, the new optimizer ("<code>BCodeOpt</code>") improves performance today, while leaving the open the door to future developments (by handling lambdas in a manner that's forward-compatible with MethodHandles).</p>

<p>Additionally, the new optimizer is more maintainable: it consists of several focused, individually simple, transformations; that are combined to implement bytecode-level refactorings, using ASM <a href="http://asm.ow2.org/">http://asm.ow2.org/</a></p>

<h2>
<a name="12-and-a-faster-code-emitter-too" class="anchor" href="#12-and-a-faster-code-emitter-too"><span class="octicon octicon-link"></span></a>1.2 And a faster code emitter, too</h2>

<p>Before the new optimizer runs (<code>BCodeOpt</code>) the new bytecode emitter (<code>GenBCode</code>) turns Abstract Syntax Trees directly into ASM Trees, outperforming by 30% its existing counterpart (<code>GenICode + GenASM</code>).</p>

<ul>
<li>the intermediate step to build Control Flow Graphs is not needed,</li>
<li>disk writing and class file building overlap (the more source files, the larger the speedup)</li>
</ul><h2>
<a name="13-leaner-closure-asts" class="anchor" href="#13-leaner-closure-asts"><span class="octicon octicon-link"></span></a>1.3 Leaner Closure ASTs</h2>

<p>The release version of <code>scalac</code> processes closures by creating inner classes early in the compilation pipeline (the "traditional" approach to closure conversion). Instead, the new backend postpones the creation of AST nodes for closures, simplifying the job of specialization, erasure, and other compiler phases. </p>

<p>Under "modern" closure conversion, the  bytecode emitter takes responsibility for producing the JVM-level representation of closures. This is the default (compiler option <code>-Yclosurify:delegating</code> ).</p>

<h1>
<a name="2-whats-new-in-the-new-optimizer" class="anchor" href="#2-whats-new-in-the-new-optimizer"><span class="octicon octicon-link"></span></a><a name="WhatsNew">2</a> What's new in the new optimizer</h1>

<h2>
<a name="21-distinction-between-intra-program-and-cross-library-optimizations" class="anchor" href="#21-distinction-between-intra-program-and-cross-library-optimizations"><span class="octicon octicon-link"></span></a>2.1 Distinction between intra-program and cross-library optimizations</h2>

<p>The existing inliner, once activated, will inline both callees found in external libraries (against which the program is being compiled) as well as callees in the program being compiled. There's no way to tell it to focus only in the intra-program case. The advantage of applying intra-program optimizations only is that at runtime updated libraries may be used (granted, binary compatible ones).</p>

<ul>
<li>intra-program optimizations   are activated via <code>-Ybackend:o2</code>
</li>
<li>cross-libraries optimizations are activated via <code>-Ybackend:o3</code>
</li>
</ul><p>Details in Sec. 4.1.</p>

<h2>
<a name="22-inlining" class="anchor" href="#22-inlining"><span class="octicon octicon-link"></span></a>2.2 Inlining</h2>

<p>The inliner currently used in scalac has a few problems:</p>

<ul>
<li>closure elimination is implemented as repeated method inlinings. Upon being forced to stop with that (e.g., recursive method) none of the previous inlinings is undone, leaving both the closure class and a trail of duplicate code.</li>
<li>code may be inlined from third-party libraries or the JDK. In general methods not marked <code>@inline</code> may be inlined as discussed in thread <a href="https://groups.google.com/d/topic/scala-internals/uyFWFRbUD0o/discussion">the perils of inlining</a> </li>
<li>invocation cycles (ie M1() calling M2() calling M1() etc) are "broken" only after hitting the maximum method size threshold, leaving a trail of duplicate code behind.</li>
</ul><p>Instead, the new optimizer just follows a simple principle:</p>

<blockquote>
<p>only inline @inline-marked methods, and always inline them, including under separate-compilation</p>
</blockquote>

<p>Thus the new inliner is deterministic, not dependent on heuristics about method sizes or similar. The only additional requirement (if you will) is that the method to dispatch (the one marked <code>@inline</code>) can be found via the static type of the receiver, e.g. in a <code>Range.foreach()</code> callsite the type of the receiver must be <code>Range</code> or subtype (in general, not a super type where the <code>@inline</code> method is defined). After all, inlining is a conscious decision: making that explicit via the type of the receiver is straightforward. As a result, the <code>@noinline</code> annotation doesn't play a role anymore.</p>

<p>The new optimizer provides detailed logging about performed inlinings, as well as diagnostics when inlining proves unfeasible (down to the culprit bytecode instructions). With that, fixing the causes of non-inlining takes way less effort, as the following shows.</p>

<p>Log example:</p>

<pre><code>[log jvm] Successful closure-inlining (albeit null receiver couldn't be ruled out). Callsite: 
  scala/tools/nsc/Global.exitingTyper(Lscala/Function0;)Ljava/lang/Object;
occurring in method
  scala/tools/nsc/interpreter/JLineCompletion$CompilerCompletion$class::memberNamed(Lscala/tools/nsc/interpreter/JLineCompletion$CompilerCompletion;Ljava/lang/String;)Lscala/reflect/internal/Symbols$Symbol;
</code></pre>

<p>Warning example:</p>

<pre><code>SpecializeTypes.scala:1166: warning: Closure-inlining failed because
  scala/collection/immutable/List::mapConserve(Lscala/Function1;)Lscala/collection/immutable/List;
contains instruction 
  INVOKESPECIAL scala/collection/immutable/List.loop$1 (Lscala/collection/mutable/ListBuffer;Lscala/collection/immutable/List;Lscala/collection/immutable/List;Lscala/Function1;)Lscala/collection/immutable/List;
that would cause IllegalAccessError from class scala/tools/nsc/transform/SpecializeTypes
        val parents1 = parents mapConserve specializedType
                               ^
</code></pre>

<p>The warning makes sense: <code>loop()</code> is a local method:</p>

<div class="highlight highlight-scala"><pre><span class="c1">// scala.collection.immutable.List</span>
  <span class="nd">@inline</span> <span class="k">final</span> <span class="k">def</span> <span class="n">mapConserve</span><span class="o">[</span><span class="kt">B</span> <span class="k">&gt;:</span> <span class="kt">A</span> <span class="k">&lt;:</span> <span class="kt">AnyRef</span><span class="o">](</span><span class="n">f</span><span class="k">:</span> <span class="kt">A</span> <span class="o">=&gt;</span> <span class="n">B</span><span class="o">)</span><span class="k">:</span> <span class="kt">List</span><span class="o">[</span><span class="kt">B</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
    <span class="nd">@tailrec</span>
    <span class="k">def</span> <span class="n">loop</span><span class="o">(</span><span class="n">mapped</span><span class="k">:</span> <span class="kt">ListBuffer</span><span class="o">[</span><span class="kt">B</span><span class="o">],</span> <span class="n">unchanged</span><span class="k">:</span> <span class="kt">List</span><span class="o">[</span><span class="kt">A</span><span class="o">],</span> <span class="n">pending</span><span class="k">:</span> <span class="kt">List</span><span class="o">[</span><span class="kt">A</span><span class="o">])</span><span class="k">:</span> <span class="kt">List</span><span class="o">[</span><span class="kt">B</span><span class="o">]</span> <span class="k">=</span>
       <span class="o">...</span>
</pre></div>

<p>The bytecode-level counterpart, <code>loop$1()</code>, was emitted as private, as javap output shows:</p>

<pre lang="javap"><code>private final
scala.collection.immutable.List
loop$1(scala.collection.mutable.ListBuffer,
       scala.collection.immutable.List,
       scala.collection.immutable.List,
       scala.Function1);
  ...
</code></pre>

<h2>
<a name="23-gc-savvy-closures-singleton-closures-minimization-of-closure-state" class="anchor" href="#23-gc-savvy-closures-singleton-closures-minimization-of-closure-state"><span class="octicon octicon-link"></span></a>2.3 GC-savvy closures: Singleton closures, Minimization of closure state</h2>

<p>Some anonymous closures depend only on <code>apply()</code> arguments, for example the char filter function:</p>

<div class="highlight highlight-scala"><pre>  <span class="k">def</span> <span class="n">deeplyNestedMethod</span><span class="o">(</span><span class="n">str</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
    <span class="n">str</span> <span class="n">filter</span> <span class="o">{</span>
      <span class="o">(</span><span class="n">char</span><span class="k">:</span> <span class="kt">Char</span><span class="o">)</span> <span class="k">=&gt;</span>
        <span class="o">(</span><span class="n">char</span> <span class="o">&gt;=</span> <span class="-Symbol">'a</span><span class="err">'</span> <span class="o">&amp;&amp;</span> <span class="n">char</span> <span class="o">&lt;=</span> <span class="-Symbol">'f</span><span class="err">'</span><span class="o">)</span> <span class="o">||</span>
        <span class="o">(</span><span class="n">char</span> <span class="o">&gt;=</span> <span class="-Symbol">'A</span><span class="err">'</span> <span class="o">&amp;&amp;</span> <span class="n">char</span> <span class="o">&lt;=</span> <span class="-Symbol">'F</span><span class="err">'</span><span class="o">)</span> <span class="o">||</span>
        <span class="o">(</span><span class="n">char</span> <span class="o">&gt;=</span> <span class="sc">'0'</span> <span class="o">&amp;&amp;</span> <span class="n">char</span> <span class="o">&lt;=</span> <span class="sc">'9'</span><span class="o">)</span> <span class="o">}</span>
  <span class="o">}</span>
</pre></div>

<p>In these cases, the new optimizer avoids repeated allocations by keeping (in a static field) a singleton-instance that is reused.</p>

<p>After dead-code elimination, closure state comprises only what is actually accessed.</p>

<p>These features are more useful on Android (besides micro-benchmarks) where a vast RAM doesn't masquerade redundant allocations.</p>

<h2>
<a name="24-supported-optimizations" class="anchor" href="#24-supported-optimizations"><span class="octicon octicon-link"></span></a>2.4 Supported optimizations</h2>

<h3>
<a name="241-intra-method-optimizations" class="anchor" href="#241-intra-method-optimizations"><span class="octicon octicon-link"></span></a>2.4.1 Intra-method optimizations</h3>

<ul>
<li>collapse a multi-jump chain to target its final destination via a single jump</li>
<li>remove unreachable code</li>
<li>remove those <code>LabelNodes</code> and <code>LineNumbers</code> that aren't in use</li>
<li>remove dangling exception handlers</li>
<li>copy propagation</li>
<li>dead-store elimination</li>
<li>Preserve side-effects, but remove those (producer, consumer) pairs where the consumer is a <code>DROP</code> and
the producer has its value consumed only by the <code>DROP</code> in question.</li>
<li>simplify branches that need not be taken to get to their destination.</li>
<li>nullness propagation</li>
<li>constant folding</li>
<li>caching repeatable reads of stable values</li>
<li>eliding box/unbox pairs</li>
<li>eliding redundant local vars</li>
</ul><h3>
<a name="242-intra-class-optimizations" class="anchor" href="#242-intra-class-optimizations"><span class="octicon octicon-link"></span></a>2.4.2 Intra-class optimizations</h3>

<ul>
<li>those private members of a class which see no use are elided</li>
<li>tree-shake unused closures, minimize the fields of those remaining</li>
<li>minimization of closure-allocations</li>
<li>refresh the InnerClasses JVM attribute</li>
</ul><h3>
<a name="243-whole-program-optimizations" class="anchor" href="#243-whole-program-optimizations"><span class="octicon octicon-link"></span></a>2.4.3 Whole-program optimizations</h3>

<ul>
<li>method inlining</li>
<li>closure inlining</li>
</ul><h1>
<a name="3-test-driving-the-new-optimizer" class="anchor" href="#3-test-driving-the-new-optimizer"><span class="octicon octicon-link"></span></a><a name="TestDriving">3</a> Test driving the new optimizer</h1>

<h2>
<a name="31-how-much-does-it-add-to-compilation-time" class="anchor" href="#31-how-much-does-it-add-to-compilation-time"><span class="octicon octicon-link"></span></a>3.1 How much does it add to compilation time?</h2>

<p>The new optimizer (except the whole-program step) is task-parallel:</p>

<ul>
<li>intra-method optimizations are run in parallel for different methods;</li>
<li>intra-class optimizations are run in parallel for different classes</li>
</ul><p>Visually:</p>

<p><img src="http://lampwww.epfl.ch/%7Emagarcia/ScalaCompilerCornerReloaded/yk.png" alt="experimental optimizer uses task parallelism"></p>

<p>There's no reason to limit the worker pool to 8 threads, that's configurable via <code>-Ybcode-emitter-threads N</code></p>

<h2>
<a name="32-emitted-code-size" class="anchor" href="#32-emitted-code-size"><span class="octicon octicon-link"></span></a>3.2 Emitted code size</h2>

<p>Let's take <code>scala/scala</code> as case study, compiling <code>src/compiler</code> and <code>src/reflect</code> (on the one hand) and the standard library (on the other) using:</p>

<ol>
<li>GenICode and GenASM.</li>
<li>GenBCode (highlighted).</li>
</ol><p>The new optimizer produces smaller JARs:</p>

<p><img src="http://lampwww.epfl.ch/%7Emagarcia/ScalaCompilerCornerReloaded/SizeComparison.png" alt="jar size comparison"></p>

<p>The above reflects not so much code reductions (in terms of instruction count) but smaller constant pools due to Lean Closure Classes (an LCC just delegates to the class where the anon-closure is instantiated, which usually already has the constant pool entries that under "traditional" closure conversion have to be duplicated in the anon-closure-class).</p>

<p>To benefit from code size reductions as well, <code>-Ybackend:o1</code> (intra-method optimizations) or up will do the trick. Moreover, on a multicore <code>-Ybackend:o1</code> doesn't increase appreciably compilation time, I'm actually thinking making it default.</p>

<p>For example, method <code>driver()</code> in <code>test/files/run/t7181.scala</code> results in:</p>

<ul>
<li>881 instructions, when compiled with <code>-Ybackend:o2 -Yclosurify:delegating</code>
</li>
<li>1004 instructions, when compiled with <code>-Ybackend:GenASM -optimise</code> (actually, <code>-optimise</code> increases code size, but the comparison with <code>-Ybackend:o2</code> is fair).</li>
</ul><p>That's 881 vs 1004 instructions and not bytes, which still matters in case you're the one who has to read 881 vs 1004 lines of javap output.</p>

<h2>
<a name="33-benchmarks" class="anchor" href="#33-benchmarks"><span class="octicon octicon-link"></span></a>3.3 Benchmarks</h2>

<p>Feedback is welcome!</p>

<h2>
<a name="34-speeding-up-scalac" class="anchor" href="#34-speeding-up-scalac"><span class="octicon octicon-link"></span></a>3.4 Speeding up scalac</h2>

<p>Speedups in the range 10% to 20% have been observed against the latest <code>scalac</code>. The upper range is achieved by having a compiler optimized by the new optimizer compile using <code>-Ybackend:GenBCode -Yclosurify:delegating</code> (ie unoptimized compilation, using the new bytecode emitter and Leaner Closure ASTs). Just one data point:</p>

<pre><code>[stopwatch] [locker.comp.timer: 1:43.359 sec]
...
[stopwatch] [quick.comp.timer:  1:32.335 sec]
</code></pre>

<p>Right now the new optimizer alone makes scalac only marginally faster. Instead, the 15% speedup mentioned above is due to the compiler doing less work: (a) Leaner Closure ASTs, (b) the new bytecode emitter, and (c) lower GC overhead. That's normal: <code>scalac</code> is dominated by factors not optimizable (at least not in the short term). Examples abound: </p>

<ul>
<li>millions of <code>::</code> allocated. Neither the old nor the new optimizer are tuned to reduce that.</li>
<li>for deeper insights:  <a href="https://github.com/gkossakowski/scalac-aspects">https://github.com/gkossakowski/scalac-aspects</a>
</li>
<li>actually, tools like Caliper or ScalaMeter, by themselves, tell how much faster something runs. When building an optimizer, it's more useful to know "why" something runs faster (specially with 20+ optimizations at play). With some work, the toolset that Grzegorz has jumpstarted can provide those insights. </li>
</ul><p>The new optimizer may well make <em>your</em> code run faster. To find out, give it a try.</p>

<h2>
<a name="35-bugs-fixed" class="anchor" href="#35-bugs-fixed"><span class="octicon octicon-link"></span></a>3.5 Bugs fixed</h2>

<ul>
<li>
<a href="https://issues.scala-lang.org/browse/SI-3882">SI-3882</a> Regression with -optimise: "Illegal index: 0 overlaps List((variable par1,LONG))" </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-5286">SI-5286</a> avoid duplicating more than once a closure body when inlining a closure</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-5850">SI-5850</a> Inlined code shouldn't forget null-check on the original receiver</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-5950">SI-5950</a> Inlining creates duplicates when anon-closure-class can't be eliminated after all</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-6105">SI-6105</a> Conditional optimization: <code>true || x == true, false &amp;&amp; y == false</code>
</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-6164">SI-6164</a> pipeline classfile building and writing (GenASM, GenBCode) </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-6191">SI-6191</a> spurious <code>SCOPE_EXIT</code> warnings</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-6288">SI-6288</a> Wrong line number information in bytecode</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-6546">SI-6546</a> Optimizer leaves references to classes that have been eliminated by inlining </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-6723">SI-6723</a> 2.10 regression: inliner warnings with Map literal and <code>-optimize</code> </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-6759">SI-6759</a> Seek clarification about necessary and sufficient conditions for inclusion in InnerClasses JVM attribute </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7050">SI-7050</a> phase closelim is a mess </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7182">SI-7182</a> Finally blocks are duplicated for each 'return' in a try/catch/finally </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7407">SI-7407</a> return inside try + pattern-match inside finally causes VerifyError</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7518">SI-7518</a> inliner destroys line number information</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7524">SI-7524</a> pathologically slow compilation time with -optimize and named/default arguments </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7540">SI-7540</a> Optimizer changes behavior when pattern matching Some(X) scrutinee when X's type assumed wrong</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7560">SI-7560</a> the ICode optimizer doesn't DCE-away trivial branches </li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7589">SI-7589</a> VerifyError under <code>-Yinline -Yinline-handlers</code>
</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7607">SI-7607</a> optimizer changes behavior of IDIV, LDIV, IREM, LREM bytecode instructions when the result is dropped<br>
</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7792">SI-7792</a> Explicit return causes scalac -optimize to fail</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-7807">SI-7807</a> java.lang.VerifyError when using nested try/catch and ControlThrowable</li>
<li>all <code>ICodeReader</code> bugs (the ASM class file reader is used instead)</li>
<li>all <code>-Ydelambdafy:method</code> bugs (the new backend doesn't require custom typing to represent lightweight-lambdas internally)

<ul>
<li>
<a href="https://issues.scala-lang.org/browse/SI-8017">SI-8017</a> -Ydelambdafy:method + lambda taking/returning a value class = kaboom</li>
<li>
<a href="https://issues.scala-lang.org/browse/SI-8034">SI-8034</a> compiler can't compile itself under -Ydelambdafy:method</li>
</ul>
</li>
</ul><h1>
<a name="4-getting-started" class="anchor" href="#4-getting-started"><span class="octicon octicon-link"></span></a><a name="GettingStarted">4</a> Getting Started</h1>

<p>The first step is checking out branch <code>GenRefactored99sR</code> of repository <a href="https://github.com/magarciaEPFL/scala">https://github.com/magarciaEPFL/scala</a></p>

<pre><code>git clone git://github.com/magarciaEPFL/scala.git GenRefactored99sR
cd GenRefactored99sR
git checkout -b GenRefactored99sR origin/GenRefactored99sR
ant all.clean &amp;&amp; ant
</code></pre>

<h2>
<a name="40-using-sbt-to-build-your-project-with-the-new-backend--optimizer" class="anchor" href="#40-using-sbt-to-build-your-project-with-the-new-backend--optimizer"><span class="octicon octicon-link"></span></a>4.0 Using sbt to build your project with the new backend / optimizer</h2>

<p>Section <a href="http://www.scala-sbt.org/snapshot/docs/Detailed-Topics/Configuring-Scala.html">Using Scala from a local directory</a> covers the changes needed in your project's <code>Build.scala</code>:</p>

<pre><code>scalaVersion := "2.11.0-SNAPSHOT",

scalaHome := Some(file("scala-with-new-backend/build/pack")),

scalacOptions ++= Seq( . . . your options
                      "-Ybackend:o3", // the highest level of the new optimizer
                       . . . more of your options
                     ),
</code></pre>

<p>where "scala-with-new-backend" is the folder one gets after  following the steps in the sub-section above (cloning, checking out branch <code>GenRefactored99sR</code>, building the compiler with <code>ant</code>).</p>

<h2>
<a name="41-meaning-of-optimization-levels" class="anchor" href="#41-meaning-of-optimization-levels"><span class="octicon octicon-link"></span></a>4.1 Meaning of optimization levels</h2>

<p>Each optimization level includes all optimizations from lower levels, and assume the new bytecode emitter (<code>GenBCode</code>) is active:</p>

<table>
<tr>
<td><code>-Ybackend:GenASM</code></td>   <td>backdoor to use the old backend.</td> </tr>
<tr>
<td><code>-Ybackend:GenBCode</code></td> <td>use the new code emitter, just emitting trees as delivered by CleanUp</td> </tr>
<tr>
<td><code>-Ybackend:o1</code></td>       <td>Intra-method optimizations and all closure optimizations except closure stack-allocation (in detail: <code>-Ybackend:o1</code> performs minimization of closure state and closure "singletonization")</td> </tr>
<tr>
<td><code>-Ybackend:o2</code></td>       <td>Intra-program optimizations. This includes any method inlining and closure stack-allocation as long as it affects only what's being compiled, as opposed to peeking inside external libraries (see below).</td> </tr>
<tr>
<td><code>-Ybackend:o3</code></td>       <td>Cross-libraries optimization: this includes the same kinds of optimization as above, with the caveat that bytecode from external <em>can be parsed</em> if needed to apply some optimization (e.g., this is the optimization level to picks to have <code>Range.foreach</code> inlined)</td> </tr>
</table><p><em>Nota bene</em>: In order to ease migration from old to new optimizer, for now no error is emitted when mixing compiler flags for old and new optimizer. In this case the compiler silently falls back to the old optimizer. This "feature" allows keeping the test suite as is: all those tests asking for <code>-optimise</code> or one of its variants can run without modification.</p>

<h2>
<a name="42-choosing-bytecode-level-representation-of-closures" class="anchor" href="#42-choosing-bytecode-level-representation-of-closures"><span class="octicon octicon-link"></span></a>4.2 Choosing bytecode-level representation of closures</h2>

<table>
<tr>
<td><code>-Ydelambdafy:inline</code></td>   <td>Good ol' dedicated inner class for each closure. Available under GenASM (the only option there), and also with GenBCode but only up to <code>-Ybackend:o1</code>
</td> </tr>
<tr>
<td><code>-Yclosurify:delegating</code></td> <td>aka "Late Closure Classes" ie their creation is postponed (instead of UnCurry during GenBCode) thus lowering the working set during compilation. Allows closure-related optimizations (all optimization levels supported)</td> </tr>
</table><h2>
<a name="43-diagnostics" class="anchor" href="#43-diagnostics"><span class="octicon octicon-link"></span></a>4.3 Diagnostics</h2>

<p>Diagnostics are displayed via <code>-Ylog:jvm</code> , for more details add <code>-Yinline-warnings</code> and if that's not enough adding <code>-Ydebug</code> will show both the individual bytecode instructions subject of the message as well as a listing of the enclosing method (all in ASM textual format, which is always available unlike <code>javap</code>).</p>

<p>Another useful flag is <code>-Ygen-asmp &lt;folder&gt;</code> which similar to <code>-Ygen-javap</code> will emit textual files but in ASM format.</p>

<p>What others are doing:</p>

<ul>
<li><a href="http://blog.cdleary.com/2010/05/notes-from-the-js-pit-closure-optimization/">Notes from the JS pit: closure optimization</a></li>
<li><a href="http://lamp.epfl.ch/%7Emagarcia/ScalaCompilerCornerReloaded/2012Q2/RuntimeMP.pdf">Runtime metaprogramming via java.lang.invoke.MethodHandle</a></li>
<li><a href="http://www.scalabench.org/publications.html">A comparison of the memory behaviour of Java and Scala programs</a></li>
</ul><h1>
<a name="5-putting-the-new-optimizer-through-its-paces" class="anchor" href="#5-putting-the-new-optimizer-through-its-paces"><span class="octicon octicon-link"></span></a><a name="Paces">5</a> Putting the new optimizer through its paces</h1>

<h2>
<a name="51-optimizing-the-compiler-and-the-standard-library-themselves" class="anchor" href="#51-optimizing-the-compiler-and-the-standard-library-themselves"><span class="octicon octicon-link"></span></a>5.1 Optimizing the compiler and the standard library themselves</h2>

<p>An attempt to <code>ant nightly</code> on a clean checkout of branch <code>GenRefactored99sR</code> doesn't achieve the desired effect, because the old optimizer is used (<code>-optimize</code> activates the old optimizer). In fact, the compiler used for the first time to compile the new backend doesn't understand yet flags like <code>-Ybackend:o1</code>.</p>

<p>In order to run the test suite under the new optimizer, one may hardcode the optimization level of choice as shown below (run <code>ant quick.clean &amp;&amp; ant</code> for the update to take effect).</p>

<div class="highlight highlight-diff"><pre><span class="gd">--- a/src/compiler/scala/tools/nsc/settings/ScalaSettings.scala</span>
<span class="gi">+++ b/src/compiler/scala/tools/nsc/settings/ScalaSettings.scala</span>
<span class="gu">@@ -218,7 +218,7 @@ trait ScalaSettings extends AbsScalaSettings</span>
    */
   val Ybackend = ChoiceSetting ("-Ybackend", "choice of bytecode emitter", "Choice of bytecode emitter.",
                                 List("GenASM", "GenBCode", "o1", "o2", "o3"),
<span class="gd">-                                "o1")</span>
<span class="gi">+                                "o3")</span>
</pre></div>

<p>With the optimization level hardcoded as shown above, one may also delete all occurrences of "<code>-optimise</code>"  in <code>build.xml</code> and <code>build-ant-macros.xml</code>. That way, <code>ant all.clean &amp;&amp; ant &amp;&amp; ant nightly</code> will both run the test suite and build a distribution optimized under <code>BCodeOpt</code>.</p>

<h2>
<a name="52-experimental-features" class="anchor" href="#52-experimental-features"><span class="octicon octicon-link"></span></a>5.2 Experimental features</h2>

<p>In principle, method handles can help with specialization, structural types, and lambdas. The prototype in branch <code>GenMHv3</code> puts MHs to work to replace anon-closure-classes, with mixed results (the good: smaller jars; the bad: performance on JDK7). For perspective, the delta with respect to the non-MethodHandles backend is: </p>

<p><a href="https://github.com/magarciaEPFL/scala/compare/magarciaEPFL:GenRefactored14...GenMHv3">https://github.com/magarciaEPFL/scala/compare/magarciaEPFL:GenRefactored14...GenMHv3</a></p>

<p>Sources can be obtained via:</p>

<pre><code>    git clone git://github.com/magarciaEPFL/scala.git GenMHv3
    cd GenMHv3
    git checkout -b GenMHv3 origin/GenMHv3
    ant all.clean &amp;&amp; ant
</code></pre>

<p>This prototype requires <code>-target:jvm-1.7</code>. Right now scalac doesn't produce the newest class file format of JDK8. In the meantime,  <code>-target:jvm-1.7</code> can be used on that platform. A discussion about performance at: <a href="https://groups.google.com/d/msg/scala-internals/uBxprJixpwk/jG78X1k_92IJ">https://groups.google.com/d/msg/scala-internals/uBxprJixpwk/jG78X1k_92IJ</a></p>

<h1>
<a name="6-faq" class="anchor" href="#6-faq"><span class="octicon octicon-link"></span></a><a name="FAQ">6</a> FAQ</h1>

<ul>
<li>
<strong>What are those Java sources doing in package <code>scala.tools.asm.optimiz</code>?</strong> </li>
</ul><p>Those Java classes are a thin layer of functionality on top of the ASM library, which is written in Java. Package <code>scala.tools.asm.optimiz</code> contains intra-method optimizations which can be performed without knowledge about Scala-level types. The bulk of the optimizer, in constrast, is written in Scala.</p>

<ul>
<li><strong>If MethodHandles are slow on JDK7, how come other programming languages are happily using them?</strong></li>
</ul><p>There's no contradiction. Other languages use MethodHandles for what Scala would accomplish via structural types, and in that setting MHs are faster than Java reflection. Instead, the prototype described in Sec. 5.2 leverages MHs in an area far more important to Scala (anonymous closures), and in that setting they don't outperform the (yet) Lean Closure Classes that the new backend emits.</p>

<ul>
<li><strong>What about tests?</strong></li>
</ul><p>As Sec. 5.1 shows, the test suite passes under all optimization levels, from <code>-Ybackend:GenBCode</code> to <code>-Ybackend:o1</code> through <code>-Ybackend:o3</code>. It's always possible to include additional tests, for a correct optimizer: <em>they will also pass!</em> Thus if you are not convinced about the correctness argument, how about finding counter-examples? If you find one, please post it at scala-internals for discussion.</p>

<h1>
<a name="7-comments-benchmarks-test-cases-bug-reports-are-welcome" class="anchor" href="#7-comments-benchmarks-test-cases-bug-reports-are-welcome"><span class="octicon octicon-link"></span></a><a name="FeedbackWelcome">7</a> Comments, benchmarks, test cases, bug reports, are welcome.</h1>

<p>Please help us help you. Regarding additional tests, an offer you can't resist:</p>

<blockquote>
<p>In case you'd like to shoot up your Scala contributor ranking at <a href="https://github.com/scala/scala/contributors">https://github.com/scala/scala/contributors</a> consider this: YOUR TESTS ARE WELCOME !!!</p>
</blockquote>

<p>How to write bytecode-level tests? It all starts subclassing <code>BytecodeTest</code>. As an example, a unit test for constant folding:
  <a href="https://github.com/magarciaEPFL/scala/commit/3281236219ad0a7894a0c1c743e8550e2ce20dbf">https://github.com/magarciaEPFL/scala/commit/3281236219ad0a7894a0c1c743e8550e2ce20dbf</a></p>

<p>Miguel Garcia
<a href="http://lampwww.epfl.ch/%7Emagarcia">http://lampwww.epfl.ch/~magarcia</a></p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">A new backend and optimizer for scalac maintained by <a href="https://github.com/magarciaEPFL">magarciaEPFL</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
